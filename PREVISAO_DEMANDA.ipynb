{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PREVISAO_DEMANDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObHsJcfpHpq61IPhSb6hRk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaquesZanon/JOB/blob/main/PREVISAO_DEMANDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp8dlMxIA_9M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "507eA-6eBAq4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnkQ6br0BAoo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f28e5d7-d53a-4167-8865-3c7498a77d8a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODyX1ONjBAlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7a02b42-2350-4a80-8000-62c5dc932193"
      },
      "source": [
        "# Importa aquivo de texto (.txt)\n",
        "import pandas as pd\n",
        "df_original = pd.read_csv('/content/drive/MyDrive/JOB-Martins/DadosPrevisaoDemanda.csv',sep=';', decimal=',', engine='python')\n",
        "\n",
        "df_original['PrimeiraDataSemana'] = pd.to_datetime(df_original['PrimeiraDataSemana'])\n",
        "df_original['UltimaDataSemana'] = pd.to_datetime(df_original['UltimaDataSemana'])\n",
        "df_original = df_original.sort_values(by=['PrimeiraDataSemana'])\n",
        "df_original.head()\n",
        "df_original.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(183742, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djIafrr7BVfU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "1767d236-ff49-4328-c51a-6fc0e7108bed"
      },
      "source": [
        "#dat_aux = pd.DataFrame(df_reduzido.groupby(['DsDivisaoFornecedor'])['CdGrupoProdutoSimilar'].unique())\n",
        "dat_aux = pd.DataFrame(df_original.groupby(['DsDivisaoFornecedor'])['CdGrupoProdutoSimilar'].unique())\n",
        "dat_aux"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CdGrupoProdutoSimilar</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DsDivisaoFornecedor</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA</th>\n",
              "      <td>[805, 97145, 803, 88, 818, 97147, 406632, 9714...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA - DIV. FITAS</th>\n",
              "      <td>[406207, 400433, 229, 406675, 406674, 400434, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA - EPI</th>\n",
              "      <td>[9000524, 9000527, 9000531]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA - LIMPEZA</th>\n",
              "      <td>[1700717, 1704060, 1702339, 200755, 203136, 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA LIMPEZA &amp;&amp;MP</th>\n",
              "      <td>[1702629, 1701347, 1701348, 1701261, 1701262, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WHIRLPOOL S.A - L.BCA</th>\n",
              "      <td>[636, 1041, 191, 2217224, 1793, 1794, 2213230,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WORLD COM IND MED VET COSM LIM</th>\n",
              "      <td>[701869, 701761, 701768, 701767, 701762, 70176...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WOW INDUSTRIA E COMERCIO LTDA</th>\n",
              "      <td>[1600715, 1600716, 1600609, 1600455, 1600390, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XERYUS IMP.E DIST.ARTIGOS VEST.LTDA</th>\n",
              "      <td>[804284, 804051, 804057, 804061]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZOETIS IND.PROD.VETERINARIOS LTDA</th>\n",
              "      <td>[704590, 704400, 701445, 703310, 702020, 70039...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>441 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 CdGrupoProdutoSimilar\n",
              "DsDivisaoFornecedor                                                                   \n",
              "3M DO BRASIL LTDA                    [805, 97145, 803, 88, 818, 97147, 406632, 9714...\n",
              "3M DO BRASIL LTDA - DIV. FITAS       [406207, 400433, 229, 406675, 406674, 400434, ...\n",
              "3M DO BRASIL LTDA - EPI                                    [9000524, 9000527, 9000531]\n",
              "3M DO BRASIL LTDA - LIMPEZA          [1700717, 1704060, 1702339, 200755, 203136, 20...\n",
              "3M DO BRASIL LTDA LIMPEZA &&MP       [1702629, 1701347, 1701348, 1701261, 1701262, ...\n",
              "...                                                                                ...\n",
              "WHIRLPOOL S.A - L.BCA                [636, 1041, 191, 2217224, 1793, 1794, 2213230,...\n",
              "WORLD COM IND MED VET COSM LIM       [701869, 701761, 701768, 701767, 701762, 70176...\n",
              "WOW INDUSTRIA E COMERCIO LTDA        [1600715, 1600716, 1600609, 1600455, 1600390, ...\n",
              "XERYUS IMP.E DIST.ARTIGOS VEST.LTDA                   [804284, 804051, 804057, 804061]\n",
              "ZOETIS IND.PROD.VETERINARIOS LTDA    [704590, 704400, 701445, 703310, 702020, 70039...\n",
              "\n",
              "[441 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjAFSVZqBAi4"
      },
      "source": [
        "# Precisamos instalar algumas Bibliotecas\n",
        "!pip install utils\n",
        "!pip install pmdarima # para autoARIMA\n",
        "!pip install pyEDM # Para Empirical Dynamic Modeling\n",
        "!pip install croston\n",
        "!pip install gluonts # PAra DeepAR\n",
        "!pip install mxnet # PAra Deep AR\n",
        "!pip install prophet\n",
        "!pip install tqdm\n",
        "!pip install sklearn\n",
        "!pip install --upgrade mxnet~=1.7 gluonts\n",
        "!pip install darts\n",
        "!pip install 'u8darts[all]'\n",
        "!pip install skedm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni1fZBPsBZi2"
      },
      "source": [
        "def percentage_error(actual, predicted):\n",
        "    res = np.empty(actual.shape)\n",
        "    for j in range(actual.shape[0]):\n",
        "        if actual[j] != 0:\n",
        "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
        "        else:\n",
        "            res[j] = predicted[j] / np.mean(actual)\n",
        "    return res\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred): \n",
        "    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred)))) * 100"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxR78BYMBAgG"
      },
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pmdarima as pm\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "#from sklearn.metrics import mean_absolute_percentage_error \n",
        "from sklearn.metrics import r2_score\n",
        "from croston import croston\n",
        "from prophet import Prophet\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import pyEDM\n",
        "from darts import TimeSeries\n",
        "from darts.metrics import mape\n",
        "from darts.models import (\n",
        "    NaiveSeasonal,\n",
        "    NaiveDrift,\n",
        "    ExponentialSmoothing,\n",
        "    ARIMA,\n",
        "    AutoARIMA,\n",
        "    RegressionEnsembleModel,\n",
        "    RegressionModel,\n",
        "    Theta,\n",
        "    FFT\n",
        ")\n",
        "import skedm as edm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBnFqB6LBAdI"
      },
      "source": [
        "par={}\n",
        "erro_arima={}\n",
        "par_croston={}\n",
        "erro_croston={}\n",
        "erro_prophet={}\n",
        "erro_EDM = {}\n",
        "erro_naive = {}\n",
        "erro_ExponentialSmoothing = {}\n",
        "erro_Theta = {}\n",
        "erro_FFT = {}\n",
        "\n",
        "\n",
        "#for j, i in zip(tqdm (range(0, 7),desc=\"Processando Fornecedor\", ascii=False, ncols=75), tqdm (range(0,len(dat_aux.iloc[j,0])),desc=\"Processando Id Oriduto\", ascii=False, ncols=75)):\n",
        "\n",
        "for j in tqdm (range(0, 30),desc=\"Processando Fornecedor\", ascii=False, ncols=75):\n",
        "  \n",
        "    try:\n",
        "   # Selecionando os dados para ajustar os modelos\n",
        "         filter1 = df_original[\"DsDivisaoFornecedor\"]==dat_aux.index[j]\n",
        "         #filter1 = df_original[\"DsDivisaoFornecedor\"]=='SAINT GOBAIN DO BRASIL PRODUTOS IND'\n",
        "         df_0 = df_original[filter1]\n",
        "         df = df_0.groupby(['Semanas'])[['VlTotalBruto']].sum()\n",
        "         we = pd.DataFrame(list(range(1,65,1)))\n",
        "         we.columns=['Semanas']\n",
        "         we.index=we.Semanas\n",
        "         df = pd.concat([df, we], axis=1)\n",
        "         df=df['VlTotalBruto']\n",
        "         df.index = pd.DataFrame(pd.date_range('2020-01-05', freq='7D', periods=64), columns=['date']).iloc[:,0]\n",
        "         df = pd.DataFrame(df).fillna(0)\n",
        "\n",
        "      # Substituindo outliers\n",
        "         z = np.abs(stats.zscore(df.VlTotalBruto))\n",
        "         median=df.VlTotalBruto.median()\n",
        "         df[\"VlTotalBruto\"] = np.where(z>3, median, df[\"VlTotalBruto\"])\n",
        "\n",
        "      # Sets de treino e teste\n",
        "         train_len = int(df.shape[0] * 0.7)\n",
        "         train_data, test_data = df[:train_len], df[train_len:]\n",
        "\n",
        "      # Ajustando AutoArima\n",
        "         stepwise_fit = pm.auto_arima(train_data, start_p=1, start_q=1, max_p=3, max_q=3, m=12,\n",
        "                             start_P=0, seasonal=True, d=1, D=1, trace=False,\n",
        "                             error_action='ignore',  # don't want to know if an order does not work\n",
        "                             suppress_warnings=True,  # don't want convergence warnings\n",
        "                             stepwise=True)  # set to stepwise\n",
        "   \n",
        "      # Armazenando resultados AutoArima\n",
        "         sentence = [str(dat_aux.index[j])]\n",
        "         sentence = '-'.join(sentence)\n",
        "         aux = stepwise_fit.get_params()\n",
        "         par[sentence]=aux\n",
        "         forecasts = stepwise_fit.predict(test_data.shape[0])\n",
        "         mmae = mean_absolute_percentage_error(list(list(test_data.VlTotalBruto)), list(forecasts))\n",
        "         erro_arima[sentence]=mmae\n",
        "         \n",
        "  \n",
        "      # Ajustando modelo Croston\n",
        "         croston_pred = croston.fit_croston(df+0.000001,test_data.shape[0],'original')\n",
        "\n",
        "      # Armazenando resultados Croston\n",
        "         par_croston[sentence] = croston_pred\n",
        "         erro_croston[sentence] = mean_absolute_percentage_error(list(test_data.VlTotalBruto), croston_pred['croston_forecast'])\n",
        "\n",
        "      # O modelo profet sÃ³ funciona com duas colunas\n",
        "         y = df.reset_index(drop=False)\n",
        "         y.columns = ['ds', 'y']\n",
        "         #y['floor'] = 0\n",
        "         #y['cap'] = 200000\n",
        "         train = y.iloc[:train_data.shape[0],:]\n",
        "         test = y.iloc[train_data.shape[0]:,:]\n",
        "\n",
        "      #Ajustando modelo Prophet\n",
        "         m = Prophet(weekly_seasonality = True,\n",
        "                     yearly_seasonality = False,\n",
        "                     daily_seasonality = False)\n",
        "         m.fit(train,verbose=0)\n",
        "         future = m.make_future_dataframe(periods=len(test))\n",
        "         future['ds'] = pd.to_datetime(future['ds']).dt.date\n",
        "         forecast = m.predict(future)\n",
        "         one=test['y']\n",
        "         twi=list(forecast.loc[:test_data.shape[0]-1,'yhat'])\n",
        "         erro_prophet[sentence] = mean_absolute_percentage_error(list(one),list(twi))\n",
        "         \n",
        "\n",
        "         # O EDM agora, preparando o imput\n",
        "         y = y[[\"ds\",\"y\"]]\n",
        "         y.columns = [\"Time\", \"Revenue\"]\n",
        "         y.Time = list(range(1,df.shape[0]+1,1))\n",
        "         aaa=pyEDM.EmbedDimension(dataFrame = y, lib=\"1 44\", pred=\"45 64\", columns=\"Revenue\",target = \"Revenue\",showPlot=False)\n",
        "         maxE = aaa.rho.max()\n",
        "         selectedE=aaa[aaa.rho==maxE]['E']\n",
        "         X = y.Revenue+0.000001\n",
        "         E = edm.Embed(X) #initiate the class\n",
        "         max_lag = 20\n",
        "         mi = E.mutual_information(max_lag)\n",
        "         mi = pd.DataFrame(mi)\n",
        "         mi['lag'] = range(0,20,1)\n",
        "         mi.columns = [\"mi\", \"lag\"]\n",
        "         maxMI = mi.mi.max()\n",
        "         selectedMI=mi[mi.mi==maxMI]['lag']\n",
        "         lag = int(selectedMI)\n",
        "         embed = int(selectedE)\n",
        "         predict = 20 #predicting out to double to lag\n",
        "         X,y = E.embed_vectors_1d(1 if lag==0 else lag,3 if embed>5 else embed,predict)\n",
        "         #split it into training and testing sets\n",
        "         train_len = int(.70*len(X))\n",
        "         Xtrain = X[0:train_len]\n",
        "         ytrain = y[0:train_len]\n",
        "         Xtest = X[train_len:]\n",
        "         ytest = y[train_len:]\n",
        "\n",
        "         weights = 'distance' #use a distance weighting for the near neighbors\n",
        "         M = edm.Regression(weights) # initiate the nonlinear forecasting class\n",
        "         M.fit(Xtrain, ytrain) #fit the data (rebuilding the attractor)\n",
        "\n",
        "         nn_list = [20]\n",
        "         ypred = M.predict(Xtest,nn_list)\n",
        "         ypred = pd.DataFrame(ypred[0])\n",
        "         ypred.mean(axis=0)\n",
        "         ypred = ypred.mean(axis=0)\n",
        "         erro_EDM[sentence] = mean_absolute_percentage_error(list(df.VlTotalBruto[44:]),list(ypred))\n",
        "\n",
        "         # PAra Naive, Prophet, exponential smothing, theta, FFT\n",
        "         series = TimeSeries.from_dataframe(df.reset_index(), 'date', 'VlTotalBruto')\n",
        "         train2, val = series.split_after(0.7)\n",
        "         model1 = NaiveDrift()\n",
        "         model1.fit(train2+0.00000001)\n",
        "         pred_val1 = model1.predict(len(val))\n",
        "         erro_naive[sentence] = str(mape(pred_val1, val))\n",
        "\n",
        "         model2 = ExponentialSmoothing()\n",
        "         model2.fit(train2+0.00000001)\n",
        "         pred_val2 = model2.predict(len(val))\n",
        "         erro_ExponentialSmoothing[sentence] = str(mape(pred_val2, val))\n",
        "\n",
        "         model3 = Theta()\n",
        "         model3.fit(train2+0.00000001)\n",
        "         pred_val3 = model3.predict(len(val))\n",
        "         erro_Theta[sentence] = str(mape(pred_val3, val))\n",
        "\n",
        "         model4 = FFT(trend='poly',trend_poly_degree = 3)\n",
        "         model4.fit(train2+0.00000001)\n",
        "         pred_val4 = model4.predict(len(val))\n",
        "         erro_FFT[sentence] = str(mape(pred_val4, val))\n",
        "\n",
        "    except:\n",
        "      pass  \n",
        "\n",
        "resultado_final =pd.concat([pd.DataFrame.from_dict(erro_arima,orient='index'),\n",
        "           pd.DataFrame.from_dict(erro_croston,orient='index'),\n",
        "           pd.DataFrame.from_dict(erro_prophet,orient='index'),\n",
        "           pd.DataFrame.from_dict(erro_EDM,orient='index'),\n",
        "           pd.DataFrame.from_dict(erro_naive,orient='index'),\n",
        "           pd.DataFrame.from_dict(erro_ExponentialSmoothing,orient='index'),\n",
        "           pd.DataFrame.from_dict(erro_Theta,orient='index'),\n",
        "           pd.DataFrame.from_dict(erro_FFT,orient='index')   \n",
        "           ], axis=1)\n",
        "resultado_final.columns=[\"arima\",\"croston\", \"prophet\",\"EDM\",\"naive\",\"ExpSmooth\",\"theta\",\"fft\"]\n",
        "resultado_final.to_csv('/content/drive/MyDrive/JOB-Martins/rfesultado_final.csv')\n",
        "#pd.DataFrame.from_dict(erro_prophet,orient='index').to_csv('/content/drive/MyDrive/JOB-Martins/prophet.csv')\n",
        "#pd.DataFrame.from_dict(erro_croston,orient='index').to_csv('/content/drive/MyDrive/JOB-Martins/croston.csv')\n",
        "#pd.DataFrame.from_dict(erro,orient='index').to_csv('/content/drive/MyDrive/JOB-Martins/arima.csv')\n",
        "#pd.DataFrame.from_dict(erro_EDM,orient='index').to_csv('/content/drive/MyDrive/JOB-Martins/EDM.csv')\n",
        "print('Cmplete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "4EKp15AyUA8w",
        "outputId": "b7f71b7b-4099-4009-ea37-c9db485866c4"
      },
      "source": [
        "resultado_final"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arima</th>\n",
              "      <th>croston</th>\n",
              "      <th>prophet</th>\n",
              "      <th>EDM</th>\n",
              "      <th>naive</th>\n",
              "      <th>ExpSmooth</th>\n",
              "      <th>theta</th>\n",
              "      <th>fft</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA</th>\n",
              "      <td>117.648262</td>\n",
              "      <td>80.636759</td>\n",
              "      <td>71.223820</td>\n",
              "      <td>68.200139</td>\n",
              "      <td>43.953626842901464</td>\n",
              "      <td>346.66924244387144</td>\n",
              "      <td>82.74140395702209</td>\n",
              "      <td>61.86118781887762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA - DIV. FITAS</th>\n",
              "      <td>68.634331</td>\n",
              "      <td>92.893982</td>\n",
              "      <td>47.505311</td>\n",
              "      <td>55.554885</td>\n",
              "      <td>80.55838450623207</td>\n",
              "      <td>329.3402806235214</td>\n",
              "      <td>69.40219544796324</td>\n",
              "      <td>1212.3236090212094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA - EPI</th>\n",
              "      <td>360.773556</td>\n",
              "      <td>91.197741</td>\n",
              "      <td>27.782731</td>\n",
              "      <td>73.647905</td>\n",
              "      <td>328863157984.2105</td>\n",
              "      <td>157.41435385992284</td>\n",
              "      <td>261.9962036807411</td>\n",
              "      <td>137.7668314501699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA - LIMPEZA</th>\n",
              "      <td>67.036057</td>\n",
              "      <td>81.204552</td>\n",
              "      <td>58.078016</td>\n",
              "      <td>59.806057</td>\n",
              "      <td>247.27460880537234</td>\n",
              "      <td>6364.5696651361595</td>\n",
              "      <td>245.19914847062404</td>\n",
              "      <td>32.36623149911417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA LIMPEZA &amp;&amp;MP</th>\n",
              "      <td>4200.195607</td>\n",
              "      <td>3986.676148</td>\n",
              "      <td>16594.728816</td>\n",
              "      <td>7307.277644</td>\n",
              "      <td>72331579036.8421</td>\n",
              "      <td>98.48516466093218</td>\n",
              "      <td>98.79297963377944</td>\n",
              "      <td>178.87343784235668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA-ESCOLAR</th>\n",
              "      <td>37.149749</td>\n",
              "      <td>44.861988</td>\n",
              "      <td>32.588969</td>\n",
              "      <td>29.499054</td>\n",
              "      <td>46.4016858245466</td>\n",
              "      <td>77.7880597733536</td>\n",
              "      <td>102.69171570240097</td>\n",
              "      <td>42.28997783097716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL MARTCON &amp;&amp;MP</th>\n",
              "      <td>117.808174</td>\n",
              "      <td>79.363470</td>\n",
              "      <td>64.538529</td>\n",
              "      <td>76.622197</td>\n",
              "      <td>221.1183119524998</td>\n",
              "      <td>1041.889928588655</td>\n",
              "      <td>989839848670.5315</td>\n",
              "      <td>543.4936757359745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      arima  ...                 fft\n",
              "3M DO BRASIL LTDA                117.648262  ...   61.86118781887762\n",
              "3M DO BRASIL LTDA - DIV. FITAS    68.634331  ...  1212.3236090212094\n",
              "3M DO BRASIL LTDA - EPI          360.773556  ...   137.7668314501699\n",
              "3M DO BRASIL LTDA - LIMPEZA       67.036057  ...   32.36623149911417\n",
              "3M DO BRASIL LTDA LIMPEZA &&MP  4200.195607  ...  178.87343784235668\n",
              "3M DO BRASIL LTDA-ESCOLAR         37.149749  ...   42.28997783097716\n",
              "3M DO BRASIL MARTCON &&MP        117.808174  ...   543.4936757359745\n",
              "\n",
              "[7 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fum_rNIiUAzi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqo_bb99HaJi"
      },
      "source": [
        "resultado = {}\n",
        "df_2 = df\n",
        "for j in range(0, 441):\n",
        "   filter1 = df_original[\"DsDivisaoFornecedor\"]==dat_aux.index[j]\n",
        "   df_0 = df_original[filter1]\n",
        "   df = df_0.groupby(['Semanas'])[['VlTotalBruto']].sum()\n",
        "   we = pd.DataFrame(list(range(1,65,1)))\n",
        "   we.columns=['Semanas']\n",
        "   we.index=we.Semanas\n",
        "   df = pd.concat([df, we], axis=1)\n",
        "   df=df['VlTotalBruto']\n",
        "   df.index = pd.DataFrame(pd.date_range('2020-01-05', freq='7D', periods=64), columns=['date']).iloc[:,0]\n",
        "   df = pd.DataFrame(df).fillna(0)\n",
        "   df.columns = [dat_aux.index[j]]\n",
        "   df_2[dat_aux.index[j]]=df\n",
        "   #resultado[dat_aux.index[j]] = df.reset_index()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}