{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PREVISAO_DEMANDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1FTJlZM7MX659Cer9dM8U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaquesZanon/JOB/blob/main/PREVISAO_DEMANDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wYVHLkLtrkk"
      },
      "source": [
        "# Previs√£o de Demanda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp8dlMxIA_9M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "507eA-6eBAq4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnkQ6br0BAoo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83284bfe-6421-4d55-8937-dab4bb2078a2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODyX1ONjBAlz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "610dd1f1-d6e2-4555-b916-cc0de2b99340"
      },
      "source": [
        "# Importa aquivo de texto (.txt)\n",
        "import pandas as pd\n",
        "df_original = pd.read_csv('/content/drive/MyDrive/JOB-Martins/DadosPrevisaoDemanda.csv',sep=';', decimal=',', engine='python')\n",
        "\n",
        "df_original['PrimeiraDataSemana'] = pd.to_datetime(df_original['PrimeiraDataSemana'])\n",
        "df_original['UltimaDataSemana'] = pd.to_datetime(df_original['UltimaDataSemana'])\n",
        "df_original = df_original.sort_values(by=['PrimeiraDataSemana'])\n",
        "df_original.head()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SiglaUF</th>\n",
              "      <th>DsCategoria</th>\n",
              "      <th>DsSubCategoria</th>\n",
              "      <th>CdGrupoProdutoSimilar</th>\n",
              "      <th>DsGrupoProdutoSimilar</th>\n",
              "      <th>DsMarca</th>\n",
              "      <th>DsDivisaoFornecedor</th>\n",
              "      <th>ANO</th>\n",
              "      <th>PrimeiraDataSemana</th>\n",
              "      <th>UltimaDataSemana</th>\n",
              "      <th>SemanaAno</th>\n",
              "      <th>QtdeVendida</th>\n",
              "      <th>VlTotalBruto</th>\n",
              "      <th>VlTotalLiquido</th>\n",
              "      <th>VlReceitaLiquida</th>\n",
              "      <th>Semanas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BA</td>\n",
              "      <td>ACESSORIO ELETRICO</td>\n",
              "      <td>CAIXA DE LUZ</td>\n",
              "      <td>4200765</td>\n",
              "      <td>CXA.LUZ EMB.KRONA 4X2 AM.24X1</td>\n",
              "      <td>Krona</td>\n",
              "      <td>KRONA TUBOS E CONEXOES LTDA.</td>\n",
              "      <td>2020</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>23.25</td>\n",
              "      <td>23.25</td>\n",
              "      <td>21.10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>BA</td>\n",
              "      <td>SABONETE</td>\n",
              "      <td>SABONETE EM BARRA</td>\n",
              "      <td>205138</td>\n",
              "      <td>SAB.GRANADO 12X90G GLIC.BENJO.</td>\n",
              "      <td>Granado</td>\n",
              "      <td>PONTELAND DISTRIBUICAO SA</td>\n",
              "      <td>2020</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>129.06</td>\n",
              "      <td>124.92</td>\n",
              "      <td>111.72</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>BA</td>\n",
              "      <td>SABONETE</td>\n",
              "      <td>SABONETE EM BARRA</td>\n",
              "      <td>205137</td>\n",
              "      <td>SAB.GRANADO 12X90G GLIC.AMEND.</td>\n",
              "      <td>Granado</td>\n",
              "      <td>PONTELAND DISTRIBUICAO SA</td>\n",
              "      <td>2020</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>144.30</td>\n",
              "      <td>139.68</td>\n",
              "      <td>124.92</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>BA</td>\n",
              "      <td>SABONETE</td>\n",
              "      <td>SABONETE EM BARRA</td>\n",
              "      <td>203130</td>\n",
              "      <td>SAB.GRANADO 12X90G GLIC.MEL</td>\n",
              "      <td>Granado</td>\n",
              "      <td>PONTELAND DISTRIBUICAO SA</td>\n",
              "      <td>2020</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>144.30</td>\n",
              "      <td>139.68</td>\n",
              "      <td>124.92</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>BA</td>\n",
              "      <td>SABONETE</td>\n",
              "      <td>SABONETE EM BARRA</td>\n",
              "      <td>201588</td>\n",
              "      <td>SAB.GRANADO 12X90G GLIC.CALE.</td>\n",
              "      <td>Granado</td>\n",
              "      <td>PONTELAND DISTRIBUICAO SA</td>\n",
              "      <td>2020</td>\n",
              "      <td>2020-01-05</td>\n",
              "      <td>2020-02-05</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>164.79</td>\n",
              "      <td>154.57</td>\n",
              "      <td>138.24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    SiglaUF         DsCategoria  ... VlReceitaLiquida  Semanas\n",
              "0        BA  ACESSORIO ELETRICO  ...            21.10        1\n",
              "850      BA            SABONETE  ...           111.72        1\n",
              "849      BA            SABONETE  ...           124.92        1\n",
              "848      BA            SABONETE  ...           124.92        1\n",
              "847      BA            SABONETE  ...           138.24        1\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djIafrr7BVfU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "14a635a4-8a3a-48c7-dd70-4a2f8ed8e854"
      },
      "source": [
        "#dat_aux = pd.DataFrame(df_reduzido.groupby(['DsDivisaoFornecedor'])['CdGrupoProdutoSimilar'].unique())\n",
        "dat_aux = pd.DataFrame(df_original.groupby(['DsDivisaoFornecedor'])['CdGrupoProdutoSimilar'].unique())\n",
        "dat_aux"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CdGrupoProdutoSimilar</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DsDivisaoFornecedor</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA</th>\n",
              "      <td>[805, 97145, 803, 88, 818, 97147, 406632, 9714...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA - DIV. FITAS</th>\n",
              "      <td>[406207, 400433, 229, 406675, 406674, 400434, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA - EPI</th>\n",
              "      <td>[9000524, 9000527, 9000531]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA - LIMPEZA</th>\n",
              "      <td>[1700717, 1704060, 1702339, 200755, 203136, 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3M DO BRASIL LTDA LIMPEZA &amp;&amp;MP</th>\n",
              "      <td>[1702629, 1701347, 1701348, 1701261, 1701262, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WHIRLPOOL S.A - L.BCA</th>\n",
              "      <td>[636, 1041, 191, 2217224, 1793, 1794, 2213230,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WORLD COM IND MED VET COSM LIM</th>\n",
              "      <td>[701869, 701761, 701768, 701767, 701762, 70176...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WOW INDUSTRIA E COMERCIO LTDA</th>\n",
              "      <td>[1600715, 1600716, 1600609, 1600455, 1600390, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XERYUS IMP.E DIST.ARTIGOS VEST.LTDA</th>\n",
              "      <td>[804284, 804051, 804057, 804061]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZOETIS IND.PROD.VETERINARIOS LTDA</th>\n",
              "      <td>[704590, 704400, 701445, 703310, 702020, 70039...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>441 rows √ó 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 CdGrupoProdutoSimilar\n",
              "DsDivisaoFornecedor                                                                   \n",
              "3M DO BRASIL LTDA                    [805, 97145, 803, 88, 818, 97147, 406632, 9714...\n",
              "3M DO BRASIL LTDA - DIV. FITAS       [406207, 400433, 229, 406675, 406674, 400434, ...\n",
              "3M DO BRASIL LTDA - EPI                                    [9000524, 9000527, 9000531]\n",
              "3M DO BRASIL LTDA - LIMPEZA          [1700717, 1704060, 1702339, 200755, 203136, 20...\n",
              "3M DO BRASIL LTDA LIMPEZA &&MP       [1702629, 1701347, 1701348, 1701261, 1701262, ...\n",
              "...                                                                                ...\n",
              "WHIRLPOOL S.A - L.BCA                [636, 1041, 191, 2217224, 1793, 1794, 2213230,...\n",
              "WORLD COM IND MED VET COSM LIM       [701869, 701761, 701768, 701767, 701762, 70176...\n",
              "WOW INDUSTRIA E COMERCIO LTDA        [1600715, 1600716, 1600609, 1600455, 1600390, ...\n",
              "XERYUS IMP.E DIST.ARTIGOS VEST.LTDA                   [804284, 804051, 804057, 804061]\n",
              "ZOETIS IND.PROD.VETERINARIOS LTDA    [704590, 704400, 701445, 703310, 702020, 70039...\n",
              "\n",
              "[441 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjAFSVZqBAi4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e05807c-9698-4d3a-e1e6-90ead69780e9"
      },
      "source": [
        "# Precisamos instalar algumas Bibliotecas\n",
        "!pip install utils\n",
        "!pip install pmdarima # para autoARIMA\n",
        "!pip install pyEDM # Para Empirical Dynamic Modeling\n",
        "!pip install croston\n",
        "!pip install gluonts # PAra DeepAR\n",
        "!pip install mxnet # PAra Deep AR\n",
        "!pip install prophet\n",
        "!pip install tqdm\n",
        "!pip install sklearn\n",
        "!pip install --upgrade mxnet~=1.7 gluonts\n",
        "!pip install darts\n",
        "!pip install 'u8darts[all]'\n",
        "!pip install skedm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n",
            "Collecting pmdarima\n",
            "  Downloading pmdarima-1.8.2-cp37-cp37m-manylinux1_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.5 MB 24.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.29.23)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.0.1)\n",
            "Requirement already satisfied: numpy~=1.19.0 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.4.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.24.3)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (57.2.0)\n",
            "Collecting statsmodels!=0.12.0,>=0.11\n",
            "  Downloading statsmodels-0.12.2-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.5 MB 52.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19->pmdarima) (1.15.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels!=0.12.0,>=0.11->pmdarima) (0.5.1)\n",
            "Installing collected packages: statsmodels, pmdarima\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed pmdarima-1.8.2 statsmodels-0.12.2\n",
            "Collecting pyEDM\n",
            "  Downloading pyEDM-1.9.1.0-cp37-cp37m-manylinux2010_x86_64.whl (5.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.3 MB 30.8 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.3\n",
            "  Downloading pybind11-2.7.1-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200 kB 64.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from pyEDM) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from pyEDM) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->pyEDM) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->pyEDM) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->pyEDM) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->pyEDM) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->pyEDM) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.2->pyEDM) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->pyEDM) (2018.9)\n",
            "Installing collected packages: pybind11, pyEDM\n",
            "Successfully installed pyEDM-1.9.1.0 pybind11-2.7.1\n",
            "Collecting croston\n",
            "  Downloading croston-0.1.2.3-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from croston) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from croston) (1.1.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from croston) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->croston) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->croston) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->croston) (1.15.0)\n",
            "Installing collected packages: croston\n",
            "Successfully installed croston-0.1.2.3\n",
            "Collecting gluonts\n",
            "  Downloading gluonts-0.8.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.1 MB 24.3 MB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.10.0.0\n",
            "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: holidays>=0.9 in /usr/local/lib/python3.7/dist-packages (from gluonts) (0.10.5.2)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.7/dist-packages (from gluonts) (3.2.2)\n",
            "Requirement already satisfied: tqdm~=4.23 in /usr/local/lib/python3.7/dist-packages (from gluonts) (4.41.1)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.7/dist-packages (from gluonts) (0.11.1)\n",
            "Requirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.7/dist-packages (from gluonts) (1.19.5)\n",
            "Collecting pydantic~=1.1\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.1 MB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas~=1.0 in /usr/local/lib/python3.7/dist-packages (from gluonts) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts) (2.8.1)\n",
            "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts) (2.3.2)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts) (0.2.1)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays>=0.9->gluonts) (2018.9)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays>=0.9->gluonts) (0.5.11)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->gluonts) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->gluonts) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->gluonts) (1.3.1)\n",
            "Installing collected packages: typing-extensions, pydantic, gluonts\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.7.4.3\n",
            "    Uninstalling typing-extensions-3.7.4.3:\n",
            "      Successfully uninstalled typing-extensions-3.7.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires typing-extensions~=3.7.4, but you have typing-extensions 3.10.0.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gluonts-0.8.0 pydantic-1.8.2 typing-extensions-3.10.0.0\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46.9 MB 35 kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Collecting prophet\n",
            "  Downloading prophet-1.0.1.tar.gz (65 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.29.23)\n",
            "Collecting cmdstanpy==0.9.68\n",
            "  Downloading cmdstanpy-0.9.68-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pystan~=2.19.1.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.19.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.1.5)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (3.2.2)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.0.9)\n",
            "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.3.2)\n",
            "Requirement already satisfied: holidays>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (0.10.5.2)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.7/dist-packages (from prophet) (1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from prophet) (2.8.1)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.7/dist-packages (from prophet) (4.41.1)\n",
            "Collecting ujson\n",
            "  Downloading ujson-4.0.2-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 179 kB 53.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.1.2->prophet) (2018.9)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.1.2->prophet) (0.5.11)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (2.1.3)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays>=0.10.2->prophet) (1.15.0)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->prophet) (4.0.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->prophet) (1.3.1)\n",
            "Building wheels for collected packages: prophet\n",
            "  Building wheel for prophet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prophet: filename=prophet-1.0.1-py3-none-any.whl size=6639869 sha256=0a6f240add791d333a0f5552cab13d7b3b355bc4794a3123a0cc3253ca0a1ba3\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/a0/1a/02c9ec9e3e9de6bdbb3d769d11992a6926889d71567d6b9b67\n",
            "Successfully built prophet\n",
            "Installing collected packages: ujson, cmdstanpy, prophet\n",
            "  Attempting uninstall: cmdstanpy\n",
            "    Found existing installation: cmdstanpy 0.9.5\n",
            "    Uninstalling cmdstanpy-0.9.5:\n",
            "      Successfully uninstalled cmdstanpy-0.9.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fbprophet 0.7.1 requires cmdstanpy==0.9.5, but you have cmdstanpy 0.9.68 which is incompatible.\u001b[0m\n",
            "Successfully installed cmdstanpy-0.9.68 prophet-1.0.1 ujson-4.0.2\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: mxnet~=1.7 in /usr/local/lib/python3.7/dist-packages (1.8.0.post0)\n",
            "Requirement already satisfied: gluonts in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet~=1.7) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet~=1.7) (1.19.5)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet~=1.7) (0.8.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet~=1.7) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet~=1.7) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet~=1.7) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet~=1.7) (2021.5.30)\n",
            "Requirement already satisfied: pandas~=1.0 in /usr/local/lib/python3.7/dist-packages (from gluonts) (1.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.7/dist-packages (from gluonts) (3.2.2)\n",
            "Requirement already satisfied: tqdm~=4.23 in /usr/local/lib/python3.7/dist-packages (from gluonts) (4.41.1)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.7/dist-packages (from gluonts) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions~=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from gluonts) (3.10.0.0)\n",
            "Requirement already satisfied: pydantic~=1.1 in /usr/local/lib/python3.7/dist-packages (from gluonts) (1.8.2)\n",
            "Requirement already satisfied: holidays>=0.9 in /usr/local/lib/python3.7/dist-packages (from gluonts) (0.10.5.2)\n",
            "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts) (2.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts) (1.15.0)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts) (0.2.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts) (2.8.1)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.9->gluonts) (2.1.3)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays>=0.9->gluonts) (2018.9)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays>=0.9->gluonts) (0.5.11)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->gluonts) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->gluonts) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib~=3.0->gluonts) (1.3.1)\n",
            "Collecting darts\n",
            "  Downloading darts-0.9.1-py3-none-any.whl (197 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197 kB 32.9 MB/s \n",
            "\u001b[?25hCollecting torch<1.9.0,>=1.8.0\n",
            "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 804.1 MB 2.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from darts) (1.0.1)\n",
            "Collecting requests>=2.25.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62 kB 671 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pystan<3.0.0.0,>=2.19.1.1 in /usr/local/lib/python3.7/dist-packages (from darts) (2.19.1.1)\n",
            "Collecting ipython>=7.22.0\n",
            "  Downloading ipython-7.26.0-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 786 kB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from darts) (2.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from darts) (0.12.2)\n",
            "Collecting scikit-learn>=0.24.0\n",
            "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.3 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from darts) (1.19.5)\n",
            "Collecting filterpy>=1.4.5\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 177 kB 60.8 MB/s \n",
            "\u001b[?25hCollecting scipy>=1.6.0\n",
            "  Downloading scipy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.5 MB 46 kB/s \n",
            "\u001b[?25hRequirement already satisfied: xarray>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from darts) (0.18.2)\n",
            "Collecting holidays>=0.11.0\n",
            "  Downloading holidays-0.11.2-py3-none-any.whl (142 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 142 kB 75.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pmdarima>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from darts) (1.8.2)\n",
            "Collecting pandas<1.3.0,>=1.2.0\n",
            "  Downloading pandas-1.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.9 MB 59.4 MB/s \n",
            "\u001b[?25hCollecting matplotlib>=3.4.0\n",
            "  Downloading matplotlib-3.4.2-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.3 MB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prophet>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from darts) (1.0.1)\n",
            "Collecting tqdm>=4.60.0\n",
            "  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.0->darts) (2.3.2)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.0->darts) (2.1.3)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.0->darts) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.0->darts) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.0->darts) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays>=0.11.0->darts) (2018.9)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays>=0.11.0->darts) (0.5.11)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.19-py3-none-any.whl (368 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 368 kB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->darts) (0.18.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->darts) (5.0.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->darts) (57.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->darts) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->darts) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->darts) (0.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->darts) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->darts) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->darts) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.22.0->darts) (0.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.0->darts) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.0->darts) (1.3.1)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.0->darts) (2.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.0->darts) (7.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.22.0->darts) (0.7.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima>=1.8.0->darts) (1.24.3)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima>=1.8.0->darts) (0.29.23)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.22.0->darts) (0.2.5)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.0->darts) (1.2)\n",
            "Requirement already satisfied: cmdstanpy==0.9.68 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.0->darts) (0.9.68)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.0->darts) (0.0.9)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from cmdstanpy==0.9.68->prophet>=1.0.0->darts) (4.0.2)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->prophet>=1.0.0->darts) (4.0.0.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->darts) (2.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->darts) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->darts) (2021.5.30)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.0->darts) (0.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->darts) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->darts) (1.34.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->darts) (0.36.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->darts) (1.32.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->darts) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->darts) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->darts) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->darts) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->darts) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->darts) (1.8.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.0->darts) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.0->darts) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.0->darts) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.0->darts) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.0->darts) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.0->darts) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.0->darts) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.9.0,>=1.8.0->darts) (3.10.0.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=7.22.0->darts) (0.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.0->darts) (3.5.0)\n",
            "Building wheels for collected packages: filterpy\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110475 sha256=8b7b18e919eec81b39a1aea506f3437e52221b38c6df49f5d87e2431a377ef77\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/e0/ee/a2b3c5caab3418c1ccd8c4de573d4cbe13315d7e8b0a55fbc2\n",
            "Successfully built filterpy\n",
            "Installing collected packages: requests, threadpoolctl, scipy, pandas, tqdm, scikit-learn, prompt-toolkit, matplotlib, holidays, torch, ipython, filterpy, darts\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: holidays\n",
            "    Found existing installation: holidays 0.10.5.2\n",
            "    Uninstalling holidays-0.10.5.2:\n",
            "      Successfully uninstalled holidays-0.10.5.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.19 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.26.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires cmdstanpy==0.9.5, but you have cmdstanpy 0.9.68 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed darts-0.9.1 filterpy-1.4.5 holidays-0.11.2 ipython-7.26.0 matplotlib-3.4.2 pandas-1.2.5 prompt-toolkit-3.0.19 requests-2.26.0 scikit-learn-0.24.2 scipy-1.7.1 threadpoolctl-2.2.0 torch-1.8.1 tqdm-4.62.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "matplotlib",
                  "mpl_toolkits",
                  "pandas",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting u8darts[all]\n",
            "  Downloading u8darts-0.9.1-py3-none-any.whl (198 kB)\n",
            "\u001b[?25l\r\u001b[K     |‚ñà‚ñã                              | 10 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñé                            | 20 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà                           | 30 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                         | 40 kB 36.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 51 kB 38.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 61 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 71 kB 24.9 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 81 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 92 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 102 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 112 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 122 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 133 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 143 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 153 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 163 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 174 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 184 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 194 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198 kB 28.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (0.24.2)\n",
            "Requirement already satisfied: matplotlib>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (3.4.2)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (1.19.5)\n",
            "Requirement already satisfied: xarray>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (0.18.2)\n",
            "Requirement already satisfied: statsmodels>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (0.12.2)\n",
            "Requirement already satisfied: ipython>=7.22.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (7.26.0)\n",
            "Requirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (4.62.0)\n",
            "Requirement already satisfied: filterpy>=1.4.5 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (1.4.5)\n",
            "Requirement already satisfied: pandas<1.3.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (1.2.5)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (2.26.0)\n",
            "Requirement already satisfied: holidays>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (0.11.2)\n",
            "Requirement already satisfied: pystan<3.0.0.0,>=2.19.1.1 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (2.19.1.1)\n",
            "Requirement already satisfied: pmdarima>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (1.8.2)\n",
            "Requirement already satisfied: tensorboard>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (2.5.0)\n",
            "Requirement already satisfied: prophet>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (1.0.1)\n",
            "Requirement already satisfied: torch<1.9.0,>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from u8darts[all]) (1.8.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.0->u8darts[all]) (2.8.1)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.0->u8darts[all]) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.0->u8darts[all]) (1.15.0)\n",
            "Requirement already satisfied: convertdate>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.0->u8darts[all]) (2.3.2)\n",
            "Requirement already satisfied: hijri-converter in /usr/local/lib/python3.7/dist-packages (from holidays>=0.11.0->u8darts[all]) (2.1.3)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays>=0.11.0->u8darts[all]) (2018.9)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /usr/local/lib/python3.7/dist-packages (from convertdate>=2.3.0->holidays>=0.11.0->u8darts[all]) (0.5.11)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->u8darts[all]) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->u8darts[all]) (57.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->u8darts[all]) (2.6.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->u8darts[all]) (0.1.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->u8darts[all]) (3.0.19)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->u8darts[all]) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->u8darts[all]) (5.0.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->u8darts[all]) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->u8darts[all]) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.22.0->u8darts[all]) (0.18.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.22.0->u8darts[all]) (0.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.0->u8darts[all]) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.0->u8darts[all]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.0->u8darts[all]) (0.10.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4.0->u8darts[all]) (7.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.22.0->u8darts[all]) (0.7.0)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima>=1.8.0->u8darts[all]) (0.29.23)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima>=1.8.0->u8darts[all]) (1.24.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.22.0->u8darts[all]) (0.2.5)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.0->u8darts[all]) (0.0.9)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.0->u8darts[all]) (1.2)\n",
            "Requirement already satisfied: cmdstanpy==0.9.68 in /usr/local/lib/python3.7/dist-packages (from prophet>=1.0.0->u8darts[all]) (0.9.68)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from cmdstanpy==0.9.68->prophet>=1.0.0->u8darts[all]) (4.0.2)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.7/dist-packages (from LunarCalendar>=0.0.9->prophet>=1.0.0->u8darts[all]) (4.0.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->u8darts[all]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->u8darts[all]) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.0->u8darts[all]) (2.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24.0->u8darts[all]) (2.2.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.12.0->u8darts[all]) (0.5.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->u8darts[all]) (3.3.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->u8darts[all]) (0.36.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->u8darts[all]) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->u8darts[all]) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->u8darts[all]) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->u8darts[all]) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->u8darts[all]) (1.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->u8darts[all]) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->u8darts[all]) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.0->u8darts[all]) (1.34.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.0->u8darts[all]) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.0->u8darts[all]) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.0->u8darts[all]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.0->u8darts[all]) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.0->u8darts[all]) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.0->u8darts[all]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.0->u8darts[all]) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.9.0,>=1.8.0->u8darts[all]) (3.10.0.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=7.22.0->u8darts[all]) (0.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.0->u8darts[all]) (3.5.0)\n",
            "Installing collected packages: u8darts\n",
            "Successfully installed u8darts-0.9.1\n",
            "Collecting skedm\n",
            "  Downloading skedm-0.0.3.tar.gz (14 kB)\n",
            "Building wheels for collected packages: skedm\n",
            "  Building wheel for skedm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for skedm: filename=skedm-0.0.3-py3-none-any.whl size=16719 sha256=6accdb3269789272faf6a13a2298fb3ae3ef9512558960587abba4e37fc7cfbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/41/07/4838c7b081ea5cc99c01c5b32c0e54bc684a6b4120516ef8b1\n",
            "Successfully built skedm\n",
            "Installing collected packages: skedm\n",
            "Successfully installed skedm-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v72jIGxFESKY"
      },
      "source": [
        "def smape(a, f):\n",
        "    return 1/len(a) * np.sum(2 * np.abs(f-a) / (np.abs(a) + np.abs(f))*100)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni1fZBPsBZi2"
      },
      "source": [
        "#def percentage_error(actual, predicted):\n",
        "#   res = np.empty(actual.shape)\n",
        "#    for j in range(actual.shape[0]):\n",
        "#        if actual[j] != 0:\n",
        "#            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
        "#        else:\n",
        "#            res[j] = predicted[j] / np.mean(actual)\n",
        "#    return res\n",
        "#\n",
        "#def mean_absolute_percentage_error(y_true, y_pred): \n",
        "#    return np.mean(np.abs(percentage_error(np.asarray(y_true), np.asarray(y_pred)))) * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxR78BYMBAgG"
      },
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pmdarima as pm\n",
        "#from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import r2_score\n",
        "from croston import croston\n",
        "from prophet import Prophet\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import pyEDM\n",
        "from darts import TimeSeries\n",
        "from darts.metrics import mape\n",
        "from darts.models import (\n",
        "    NaiveSeasonal,\n",
        "    NaiveDrift,\n",
        "    ExponentialSmoothing,\n",
        "    ARIMA,\n",
        "    AutoARIMA,\n",
        "    RegressionEnsembleModel,\n",
        "    RegressionModel,\n",
        "    Theta,\n",
        "    FFT\n",
        ")\n",
        "import skedm as edm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "uo_V8sO_6ulo",
        "outputId": "e4d872dd-37ff-488e-d627-eb6f4263155e"
      },
      "source": [
        "independencia = pd.DataFrame({\n",
        "  'holiday': 'independencia',\n",
        "  'ds': pd.to_datetime(['2020-09-13']),\n",
        "  'lower_window': 0,\n",
        "  'upper_window': 1,\n",
        "})\n",
        "independencia"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>holiday</th>\n",
              "      <th>ds</th>\n",
              "      <th>lower_window</th>\n",
              "      <th>upper_window</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>independencia</td>\n",
              "      <td>2020-09-13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         holiday         ds  lower_window  upper_window\n",
              "0  independencia 2020-09-13             0             1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBnFqB6LBAdI"
      },
      "source": [
        "par={}\n",
        "mape_arima={}\n",
        "par_croston={}\n",
        "mape_croston={}\n",
        "mape_prophet={}\n",
        "mape_EDM = {}\n",
        "mape_naive = {}\n",
        "mape_ExponentialSmoothing = {}\n",
        "mape_Theta = {}\n",
        "mape_FFT = {}\n",
        "\n",
        "smape_arima={}\n",
        "smape_croston={}\n",
        "smape_prophet={}\n",
        "smape_EDM = {}\n",
        "smape_naive = {}\n",
        "smape_ExponentialSmoothing = {}\n",
        "smape_Theta = {}\n",
        "smape_FFT = {}\n",
        "\n",
        "pred_arima ={}\n",
        "pred_croston = {}\n",
        "pred_prophet = {}\n",
        "pred_EDM = {}\n",
        "pred_Naive ={}\n",
        "pred_ExponentialSmoothing={}\n",
        "pred_Theta = {}\n",
        "pred_FFT = {}\n",
        "\n",
        "\n",
        "#for j, i in zip(tqdm (range(0, 7),desc=\"Processando Fornecedor\", ascii=False, ncols=75), tqdm (range(0,len(dat_aux.iloc[j,0])),desc=\"Processando Id Oriduto\", ascii=False, ncols=75)):\n",
        "\n",
        "for j in tqdm (range(0, 441),desc=\"Processando Fornecedor\", ascii=False, ncols=75):\n",
        "  \n",
        "    try:\n",
        "   # Selecionando os dados para ajustar os modelos\n",
        "         filter1 = df_original[\"DsDivisaoFornecedor\"]==dat_aux.index[j]\n",
        "         #filter1 = df_original[\"DsDivisaoFornecedor\"]=='SAINT GOBAIN DO BRASIL PRODUTOS IND'\n",
        "         df_0 = df_original[filter1]\n",
        "         df = df_0.groupby(['Semanas'])[['VlTotalBruto']].sum()\n",
        "         we = pd.DataFrame(list(range(1,65,1)))\n",
        "         we.columns=['Semanas']\n",
        "         we.index=we.Semanas\n",
        "         df = pd.concat([df, we], axis=1)\n",
        "         df=df['VlTotalBruto']\n",
        "         df.index = pd.DataFrame(pd.date_range('2020-01-05', freq='7D', periods=64), columns=['date']).iloc[:,0]\n",
        "         df = pd.DataFrame(df).fillna(0)\n",
        "\n",
        "      # Substituindo outliers\n",
        "         z = np.abs(stats.zscore(df.VlTotalBruto))\n",
        "         median=df.VlTotalBruto.median()\n",
        "         df[\"VlTotalBruto\"] = np.where(z>3, median, df[\"VlTotalBruto\"])\n",
        "\n",
        "      # Sets de treino e teste\n",
        "         train_len = int(df.shape[0] * 1)\n",
        "         train_data, test_data = df[:train_len], df[train_len:]\n",
        "         test_data = train_data\n",
        "\n",
        "      # Ajustando AutoArima\n",
        "         stepwise_fit = pm.auto_arima(train_data, start_p=1, start_q=1, max_p=3, max_q=3, m=12,\n",
        "                             start_P=0, seasonal=True, d=1, D=1, trace=False,\n",
        "                             error_action='ignore',  # don't want to know if an order does not work\n",
        "                             suppress_warnings=True,  # don't want convergence warnings\n",
        "                             stepwise=True)  # set to stepwise\n",
        "   \n",
        "      # Armazenando resultados AutoArima\n",
        "         sentence = [str(dat_aux.index[j])]\n",
        "         sentence = '-'.join(sentence)\n",
        "         aux = stepwise_fit.get_params()\n",
        "         par[sentence]=aux\n",
        "         forecasts = stepwise_fit.predict_in_sample(test_data.shape[0])\n",
        "         #mmae = smape(test_data.VlTotalBruto, forecasts)\n",
        "         mape_arima[sentence]=mean_absolute_percentage_error(list(list(test_data.VlTotalBruto)), list(forecasts))\n",
        "         pred_arima[sentence]=forecasts\n",
        "         smape_arima [sentence] = smape(test_data.VlTotalBruto, forecasts)\n",
        "\n",
        "  \n",
        "      # Ajustando modelo Croston\n",
        "         croston_pred = croston.fit_croston(df+0.000001,test_data.shape[0],'original')\n",
        "\n",
        "      # Armazenando resultados Croston\n",
        "         par_croston[sentence] = croston_pred\n",
        "         mape_croston[sentence] = mean_absolute_percentage_error(list(test_data.VlTotalBruto), croston_pred['croston_forecast'])\n",
        "         smape_croston[sentence] = smape(test_data.VlTotalBruto, pd.DataFrame(croston_pred['croston_forecast']).iloc[:,0])\n",
        "         pred_croston[sentence] = pd.DataFrame(croston_pred['croston_forecast']).iloc[:,0]\n",
        "\n",
        "\n",
        "      # O modelo profet s√≥ funciona com duas colunas\n",
        "         y = df.reset_index(drop=False)\n",
        "         y.columns = ['ds', 'y']\n",
        "         #y['floor'] = 0\n",
        "         #y['cap'] = 200000\n",
        "         train = y.iloc[:train_data.shape[0],:]\n",
        "         test = y.iloc[train_data.shape[0]:,:]\n",
        "         test=train\n",
        "\n",
        "      #Ajustando modelo Prophet\n",
        "         m = Prophet(weekly_seasonality = True,\n",
        "                     yearly_seasonality = False,\n",
        "                     daily_seasonality = False,\n",
        "                     holidays=independencia)\n",
        "         m.fit(train,verbose=0)\n",
        "         future = m.make_future_dataframe(periods=len(test))\n",
        "         future['ds'] = pd.to_datetime(future['ds']).dt.date\n",
        "         forecast = m.predict(future)\n",
        "         one=test['y']\n",
        "         twi=list(forecast.loc[:test_data.shape[0]-1,'yhat'])\n",
        "         mape_prophet[sentence] = mean_absolute_percentage_error(list(one),list(twi))# Assimetrico\n",
        "         smape_prophet[sentence] = smape(one, twi) # simmetrico\n",
        "         pred_prophet[sentence] = twi\n",
        "\n",
        "         # O EDM agora, preparando o imput\n",
        "         y = y[[\"ds\",\"y\"]]\n",
        "         y.columns = [\"Time\", \"Revenue\"]\n",
        "         y.Time = list(range(1,df.shape[0]+1,1))\n",
        "         \n",
        "         aaa=pyEDM.EmbedDimension(dataFrame = y, lib=\"1 64\", pred=\"1 64\", columns=\"Revenue\",target = \"Revenue\",showPlot=False)\n",
        "         maxE = aaa.rho.max()\n",
        "         selectedE=aaa[aaa.rho==maxE]['E']\n",
        "         intervalo = pyEDM.PredictInterval(dataFrame = y,lib=\"1 64\", pred=\"1 64\", columns=\"Revenue\", E=int(selectedE), showPlot=False)\n",
        "         maxpred = intervalo.rho.max()\n",
        "         selectedpred=intervalo[intervalo.rho==maxpred]['Tp']\n",
        "         simplex_pred = pyEDM.Simplex(dataFrame = y,lib=\"1 64\", pred=\"1 64\", E= 1 if maxE==0 else int(selectedE), columns=\"Revenue\",Tp=int(selectedpred),tau=1)\n",
        "         #print(pyEDM.ComputeError(simplex_pred['Observations'],simplex_pred['Predictions']))\n",
        "         simplex_pred = simplex_pred[['Observations','Predictions']].dropna()\n",
        "         pred_EDM[sentence] = list(simplex_pred['Predictions'])\n",
        "         mape_EDM[sentence] = mean_absolute_percentage_error(list(simplex_pred['Observations']), list(simplex_pred['Predictions']))\n",
        "         smape_EDM[sentence] = smape(simplex_pred['Observations'], simplex_pred['Predictions'])\n",
        "\n",
        "         # PAra Naive, exponential smothing, theta, FFT\n",
        "         series = TimeSeries.from_dataframe(df.reset_index(), 'date', 'VlTotalBruto')\n",
        "         train2, val = series.split_after(0.7)\n",
        "         trains2=val=series\n",
        "         model1 = NaiveDrift()\n",
        "         model1.fit(train2+0.00000001)\n",
        "         pred_val1 = model1.predict(len(val))\n",
        "         pred_Naive[sentence] = pd.DataFrame(pred_val1.values()).iloc[:,0]\n",
        "         mape_naive[sentence] = mean_absolute_percentage_error(series.values(),pred_val1.values())\n",
        "         smape_naive[sentence] = str(smape(series.values(),pred_val1.values()))\n",
        "\n",
        "         model2 = ExponentialSmoothing()\n",
        "         model2.fit(train2+0.00000001)\n",
        "         pred_val2 = model2.predict(len(val))\n",
        "         pred_ExponentialSmoothing[sentence] = pd.DataFrame(pred_val2.values()).iloc[:,0]\n",
        "         mape_ExponentialSmoothing[sentence] = mean_absolute_percentage_error(series.values(),pred_val2.values())\n",
        "         smape_ExponentialSmoothing[sentence] = str(smape(series.values(),pred_val2.values()))\n",
        "\n",
        "         model3 = Theta()\n",
        "         model3.fit(train2+0.00000001)\n",
        "         pred_val3 = model3.predict(len(val))\n",
        "         pred_Theta[sentence] = pd.DataFrame(pred_val3.values()).iloc[:,0]\n",
        "         mape_Theta[sentence] = mean_absolute_percentage_error(series.values(),pred_val3.values())\n",
        "         smape_Theta[sentence] = str(smape(series.values(),pred_val3.values()))\n",
        "\n",
        "         model4 = FFT(trend='poly',trend_poly_degree = 2)\n",
        "         model4.fit(train2+0.00000001)\n",
        "         pred_val4 = model4.predict(len(val))\n",
        "         pred_FFT[sentence] = pd.DataFrame(pred_val4.values()).iloc[:,0]\n",
        "         mape_FFT[sentence] = mean_absolute_percentage_error(series.values(),pred_val4.values())\n",
        "         smape_FFT[sentence] = str(smape(series.values(),pred_val4.values()))\n",
        "\n",
        "    except:\n",
        "      pass  \n",
        "\n",
        "resultado_final_mape= pd.concat([pd.DataFrame.from_dict(mape_arima,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_croston,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_prophet,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_EDM,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_naive,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_ExponentialSmoothing,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_Theta,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_FFT,orient='index')   \n",
        "           ], axis=1)\n",
        "resultado_final_mape.columns=[\"arima\",\"croston\", \"prophet\",\"EDM\",\"naive\",\"ExpSmooth\",\"theta\",\"fft\"]\n",
        "\n",
        "resultado_final_smape= pd.concat([pd.DataFrame.from_dict(smape_arima,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_croston,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_prophet,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_EDM,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_naive,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_ExponentialSmoothing,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_Theta,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_FFT,orient='index')   \n",
        "           ], axis=1)\n",
        "resultado_final_smape.columns=[\"arima\",\"croston\", \"prophet\",\"EDM\",\"naive\",\"ExpSmooth\",\"theta\",\"fft\"]\n",
        "\n",
        "predicoes = pd.concat([pd.DataFrame.from_dict(pred_arima,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_croston,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_prophet,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_EDM,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_Naive,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_ExponentialSmoothing,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_Theta,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_FFT,orient='index')   \n",
        "           ], axis=0)\n",
        "predicoes['modelos']= [\"arima\"]*len(pred_arima) + ['croston']*len(pred_croston) + [\"prophet\"]*len(pred_prophet) + [\"EDM\"]*len(pred_EDM) + ['naive']*len(pred_Naive) + ['ExpSmooth']*len(pred_ExponentialSmoothing) + ['theta']*len(pred_Theta) + ['fft']*len(pred_FFT)\n",
        "\n",
        "#resultado_final.to_csv('/content/drive/MyDrive/JOB-Martins/rfesultado_final.csv')\n",
        "#pd.DataFrame.from_dict(erro_prophet,orient='index').to_csv('/content/drive/MyDrive/JOB-Martins/prophet.csv')\n",
        "#pd.DataFrame.from_dict(erro_croston,orient='index').to_csv('/content/drive/MyDrive/JOB-Martins/croston.csv')\n",
        "#pd.DataFrame.from_dict(erro,orient='index').to_csv('/content/drive/MyDrive/JOB-Martins/arima.csv')\n",
        "#pd.DataFrame.from_dict(erro_EDM,orient='index').to_csv('/content/drive/MyDrive/JOB-Martins/EDM.csv')\n",
        "resultado_final_mape.to_csv('/content/drive/MyDrive/JOB-Martins/mape.csv')\n",
        "resultado_final_smape.to_csv('/content/drive/MyDrive/JOB-Martins/smape.csv')\n",
        "predicoes.to_csv('/content/drive/MyDrive/JOB-Martins/predicoes.csv')\n",
        "\n",
        "\n",
        "print('Cmplete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxb8m2ydo2Nr"
      },
      "source": [
        "predicoes['modelos']= [\"arima\"]*len(pred_arima) + ['croston']*len(pred_croston) + [\"prophet\"]*len(pred_prophet) + [\"EDM\"]*len(pred_EDM) + ['naive']*len(pred_Naive) + ['ExpSmooth']*len(pred_ExponentialSmoothing) + ['theta']*len(pred_Theta) + ['fft']*len(pred_FFT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFxd0J0vop4v"
      },
      "source": [
        "resultado_final_mape.to_csv('/content/drive/MyDrive/JOB-Martins/mape.csv')\n",
        "resultado_final_smape.to_csv('/content/drive/MyDrive/JOB-Martins/smape.csv')\n",
        "predicoes.to_csv('/content/drive/MyDrive/JOB-Martins/predicoes.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK4iaLUlFpDW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIm-p-eh4qSC"
      },
      "source": [
        "\n",
        "aaa=pyEDM.EmbedDimension(dataFrame = y, lib=\"1 64\", pred=\"1 64\", columns=\"Revenue\",target = \"Revenue\",showPlot=False)\n",
        "maxE = aaa.rho.max()\n",
        "selectedE=aaa[aaa.rho==maxE]['E']\n",
        "intervalo = pyEDM.PredictInterval(dataFrame = y,lib=\"1 64\", pred=\"1 64\", columns=\"Revenue\", E=int(selectedE), showPlot=False)\n",
        "maxpred = intervalo.rho.max()\n",
        "selectedpred=intervalo[intervalo.rho==maxpred]['Tp']\n",
        "simplex_pred = pyEDM.Simplex(dataFrame = y,lib=\"1 64\", pred=\"1 64\", E= 1 if maxE==0 else int(selectedE), columns=\"Revenue\",Tp=int(selectedpred),tau=1)\n",
        "#print(pyEDM.ComputeError(simplex_pred['Observations'],simplex_pred['Predictions']))\n",
        "simplex_pred = simplex_pred[['Observations','Predictions']].dropna()\n",
        "pred_EDM[sentence] = list(simplex_pred['Predictions'])\n",
        "mape_EDM[sentence] = mean_absolute_percentage_error(list(simplex_pred['Observations']), list(simplex_pred['Predictions']))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XMDr4L1T2x3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CwHL5Lt93Ch"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLhsLHvq6bJX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoekK8S16bDR"
      },
      "source": [
        "df_original.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqo_bb99HaJi"
      },
      "source": [
        "resultado = {}\n",
        "df_2 = df\n",
        "for j in range(0, 441):\n",
        "   filter1 = df_original[\"DsDivisaoFornecedor\"]==dat_aux.index[440]\n",
        "   df_0 = df_original[filter1]\n",
        "   df = df_0.groupby(['Semanas'])[['QtdeVendida']].sum()\n",
        "   we = pd.DataFrame(list(range(1,65,1)))\n",
        "   we.columns=['Semanas']\n",
        "   we.index=we.Semanas\n",
        "   df = pd.concat([df, we], axis=1)\n",
        "   df=df['QtdeVendida']\n",
        "   df.index = pd.DataFrame(pd.date_range('2020-01-05', freq='7D', periods=64), columns=['date']).iloc[:,0]\n",
        "   df = pd.DataFrame(df).fillna(0)\n",
        "   df.columns = [dat_aux.index[j]]\n",
        "   df_2[dat_aux.index[j]]=df\n",
        "   #resultado[dat_aux.index[j]] = df.reset_index()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X0YZ1Niyceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "4cb54857-f19c-488f-e0c2-731957493bfb"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QtdeVendida</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Semanas</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>2962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>1388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>1383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>3524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>940</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows √ó 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         QtdeVendida\n",
              "Semanas             \n",
              "1                246\n",
              "2                750\n",
              "3               1300\n",
              "4                872\n",
              "5                974\n",
              "...              ...\n",
              "60              2962\n",
              "61              1388\n",
              "62              1383\n",
              "63              3524\n",
              "64               940\n",
              "\n",
              "[64 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GS47ymnYdZNT"
      },
      "source": [
        "\n",
        "df_2.to_excel('/content/drive/MyDrive/JOB-Martins/quantidade_vendida_Series.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgoXhBYZSRJf"
      },
      "source": [
        "#list(np.where(z>3, median, df[\"VlTotalBruto\"])),list(df.VlTotalBruto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXlbbs1aSQsP"
      },
      "source": [
        "par={}\n",
        "mape_arima={}\n",
        "par_croston={}\n",
        "mape_croston={}\n",
        "mape_prophet={}\n",
        "mape_EDM = {}\n",
        "mape_naive = {}\n",
        "mape_ExponentialSmoothing = {}\n",
        "mape_Theta = {}\n",
        "mape_FFT = {}\n",
        "\n",
        "smape_arima={}\n",
        "smape_croston={}\n",
        "smape_prophet={}\n",
        "smape_EDM = {}\n",
        "smape_naive = {}\n",
        "smape_ExponentialSmoothing = {}\n",
        "smape_Theta = {}\n",
        "smape_FFT = {}\n",
        "\n",
        "pred_arima ={}\n",
        "pred_croston = {}\n",
        "pred_prophet = {}\n",
        "pred_EDM = {}\n",
        "pred_Naive ={}\n",
        "pred_ExponentialSmoothing={}\n",
        "pred_Theta = {}\n",
        "pred_FFT = {}\n",
        "\n",
        "diff_arima ={}\n",
        "diff_croston = {}\n",
        "diff_prophet = {}\n",
        "diff_EDM = {}\n",
        "diff_Naive ={}\n",
        "diff_ExponentialSmoothing={}\n",
        "diff_Theta = {}\n",
        "diff_FFT = {}\n",
        "\n",
        "\n",
        "#for j, i in zip(tqdm (range(0, 7),desc=\"Processando Fornecedor\", ascii=False, ncols=75), tqdm (range(0,len(dat_aux.iloc[j,0])),desc=\"Processando Id Oriduto\", ascii=False, ncols=75)):\n",
        "\n",
        "for j in tqdm (range(0, 440),desc=\"Processando Fornecedor\", ascii=False, ncols=75):\n",
        "  \n",
        "    try:\n",
        "   # Selecionando os dados para ajustar os modelos\n",
        "         filter1 = df_original[\"DsDivisaoFornecedor\"]==dat_aux.index[j]\n",
        "         #filter1 = df_original[\"DsDivisaoFornecedor\"]=='SAINT GOBAIN DO BRASIL PRODUTOS IND'\n",
        "         df_0 = df_original[filter1]\n",
        "         df = df_0.groupby(['Semanas'])[['VlTotalBruto']].sum()\n",
        "         we = pd.DataFrame(list(range(1,65,1)))\n",
        "         we.columns=['Semanas']\n",
        "         we.index=we.Semanas\n",
        "         df = pd.concat([df, we], axis=1)\n",
        "         df=df['VlTotalBruto']\n",
        "         df.index = pd.DataFrame(pd.date_range('2020-01-05', freq='7D', periods=64), columns=['date']).iloc[:,0]\n",
        "         df = pd.DataFrame(df).fillna(0)\n",
        "         \n",
        "\n",
        "      # Substituindo outliers\n",
        "         z = np.abs(stats.zscore(df.VlTotalBruto))\n",
        "         median=df.VlTotalBruto.median()\n",
        "         df[\"VlTotalBruto\"] = np.where(z>3, median, df[\"VlTotalBruto\"])\n",
        "\n",
        "      # Sets de treino e teste\n",
        "         #train_len = int(df.shape[0] * 1)\n",
        "         train_len = int(60)\n",
        "         train_data, test_data = df[:train_len], df[train_len:]\n",
        "         #test_data = train_data\n",
        "\n",
        "      # Ajustando AutoArima\n",
        "         stepwise_fit = pm.auto_arima(train_data, start_p=1, start_q=1, max_p=3, max_q=3, m=12,\n",
        "                             start_P=0, seasonal=True, d=1, D=1, trace=False,\n",
        "                             error_action='ignore',  # don't want to know if an order does not work\n",
        "                             suppress_warnings=True,  # don't want convergence warnings\n",
        "                             stepwise=True)  # set to stepwise\n",
        "   \n",
        "      # Armazenando resultados AutoArima\n",
        "         sentence = [str(dat_aux.index[j])]\n",
        "         sentence = '-'.join(sentence)\n",
        "         aux = stepwise_fit.get_params()\n",
        "         par[sentence]=aux\n",
        "         forecasts = stepwise_fit.predict(test_data.shape[0])\n",
        "         #mmae = smape(test_data.VlTotalBruto, forecasts)\n",
        "         mape_arima[sentence]=mean_absolute_percentage_error(list(list(test_data.VlTotalBruto)), list(forecasts))\n",
        "         pred_arima[sentence]=forecasts\n",
        "         smape_arima [sentence] = smape(test_data.VlTotalBruto, forecasts)\n",
        "         diff_arima[sentence] = sum(list(test_data.VlTotalBruto))-sum(list(forecasts))\n",
        "\n",
        "  \n",
        "      # Ajustando modelo Croston\n",
        "         croston_pred = croston.fit_croston(df+0.000001,test_data.shape[0],'original')\n",
        "\n",
        "      # Armazenando resultados Croston\n",
        "         par_croston[sentence] = croston_pred\n",
        "         mape_croston[sentence] = mean_absolute_percentage_error(list(test_data.VlTotalBruto), croston_pred['croston_forecast'])\n",
        "         smape_croston[sentence] = smape(test_data.VlTotalBruto, pd.DataFrame(croston_pred['croston_forecast']).iloc[:,0])\n",
        "         pred_croston[sentence] = pd.DataFrame(croston_pred['croston_forecast']).iloc[:,0]\n",
        "         diff_croston[sentence] = sum(list(test_data.VlTotalBruto))-sum(croston_pred['croston_forecast'])\n",
        "\n",
        "      # O modelo profet s√≥ funciona com duas colunas\n",
        "         y = df.reset_index(drop=False)\n",
        "         y.columns = ['ds', 'y']\n",
        "         #y['floor'] = 0\n",
        "         #y['cap'] = 200000\n",
        "         train = y.iloc[:train_data.shape[0],:]\n",
        "         test = y.iloc[train_data.shape[0]:,:]\n",
        "         #test=train\n",
        "\n",
        "      #Ajustando modelo Prophet\n",
        "         m = Prophet(weekly_seasonality = True,\n",
        "                     yearly_seasonality = False,\n",
        "                     daily_seasonality = False,\n",
        "                     holidays=independencia)\n",
        "         m.fit(train,verbose=0)\n",
        "         future = m.make_future_dataframe(periods=len(test))\n",
        "         future['ds'] = pd.to_datetime(future['ds']).dt.date\n",
        "         forecast = m.predict(future)\n",
        "         one=test['y']\n",
        "         twi=list(forecast.loc[:test_data.shape[0]-1,'yhat'])\n",
        "         mape_prophet[sentence] = mean_absolute_percentage_error(list(one),list(twi))# Assimetrico\n",
        "         smape_prophet[sentence] = smape(one, twi) # simmetrico\n",
        "         pred_prophet[sentence] = twi\n",
        "         diff_prophet[sentence] = sum(list(one))-sum(list(twi))\n",
        "\n",
        "\n",
        "         # O EDM agora, preparando o imput\n",
        "         y = y[[\"ds\",\"y\"]]\n",
        "         y.columns = [\"Time\", \"Revenue\"]\n",
        "         y.Time = list(range(1,df.shape[0]+1,1))\n",
        "         \n",
        "         aaa=pyEDM.EmbedDimension(dataFrame = y, lib=\"1 60\", pred=\"61 64\", columns=\"Revenue\",target = \"Revenue\",showPlot=False)\n",
        "         maxE = aaa.rho.max()\n",
        "         selectedE=aaa[aaa.rho==maxE]['E']\n",
        "         intervalo = pyEDM.PredictInterval(dataFrame = y,lib=\"1 60\", pred=\"61 64\", columns=\"Revenue\", E=int(selectedE), showPlot=False)\n",
        "         maxpred = intervalo.rho.max()\n",
        "         selectedpred=intervalo[intervalo.rho==maxpred]['Tp']\n",
        "         simplex_pred = pyEDM.Simplex(dataFrame = y,lib=\"1 56\", pred=\"57 64\", E=5, columns=\"Revenue\",Tp=4,tau=1)\n",
        "#print(pyEDM.ComputeError(simplex_pred['Observations'],simplex_pred['Predictions']))\n",
        "         simplex_pred = simplex_pred[['Observations','Predictions']].dropna()\n",
        "         pred_EDM[sentence] = list(simplex_pred['Predictions'])\n",
        "         mape_EDM[sentence] = mean_absolute_percentage_error(list(simplex_pred['Observations']), list(simplex_pred['Predictions']))\n",
        "         smape_EDM[sentence] = smape(simplex_pred['Observations'], simplex_pred['Predictions'])\n",
        "         diff_EDM[sentence]= sum(list(simplex_pred['Observations']))-sum(list(simplex_pred['Predictions']))\n",
        "\n",
        "         # PAra Naive, exponential smothing, theta, FFT\n",
        "         series = TimeSeries.from_dataframe(df.reset_index(), 'date', 'VlTotalBruto')\n",
        "         train2, val = series.split_after(0.94)\n",
        "         #trains2=val=series\n",
        "         model1 = NaiveDrift()\n",
        "         model1.fit(train2+0.00000001)\n",
        "         pred_val1 = model1.predict(len(val))\n",
        "         pred_Naive[sentence] = pd.DataFrame(pred_val1.values()).iloc[:,0]\n",
        "         mape_naive[sentence] = mean_absolute_percentage_error(val.values(),pred_val1.values())\n",
        "         smape_naive[sentence] = str(smape(val.values(),pred_val1.values()))\n",
        "         diff_Naive[sentence] = list(sum(val.values())-sum(pred_val1.values()))\n",
        "\n",
        "         model2 = ExponentialSmoothing()\n",
        "         model2.fit(train2+0.00000001)\n",
        "         pred_val2 = model2.predict(len(val))\n",
        "         pred_ExponentialSmoothing[sentence] = pd.DataFrame(pred_val2.values()).iloc[:,0]\n",
        "         mape_ExponentialSmoothing[sentence] = mean_absolute_percentage_error(val.values(),pred_val2.values())\n",
        "         smape_ExponentialSmoothing[sentence] = str(smape(val.values(),pred_val2.values()))\n",
        "         diff_ExponentialSmoothing[sentence] = list(sum(val.values())-sum(pred_val2.values()))\n",
        "\n",
        "         model3 = Theta()\n",
        "         model3.fit(train2+0.00000001)\n",
        "         pred_val3 = model3.predict(len(val))\n",
        "         pred_Theta[sentence] = pd.DataFrame(pred_val3.values()).iloc[:,0]\n",
        "         mape_Theta[sentence] = mean_absolute_percentage_error(val.values(),pred_val3.values())\n",
        "         smape_Theta[sentence] = str(smape(val.values(),pred_val3.values()))\n",
        "         diff_Theta[sentence] = list(sum(val.values())-sum(pred_val3.values()))\n",
        "\n",
        "         model4 = FFT(trend='poly',trend_poly_degree = 2)\n",
        "         model4.fit(train2+0.00000001)\n",
        "         pred_val4 = model4.predict(len(val))\n",
        "         pred_FFT[sentence] = pd.DataFrame(pred_val4.values()).iloc[:,0]\n",
        "         mape_FFT[sentence] = mean_absolute_percentage_error(val.values(),pred_val4.values())\n",
        "         smape_FFT[sentence] = str(smape(val.values(),pred_val4.values()))\n",
        "         diff_FFT[sentence] = list(sum(val.values())-sum(pred_val4.values()))\n",
        "\n",
        "    except:\n",
        "     pass  \n",
        "\n",
        "resultado_final_mape= pd.concat([pd.DataFrame.from_dict(mape_arima,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_croston,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_prophet,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_EDM,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_naive,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_ExponentialSmoothing,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_Theta,orient='index'),\n",
        "           pd.DataFrame.from_dict(mape_FFT,orient='index')   \n",
        "           ], axis=1)\n",
        "resultado_final_mape.columns=[\"arima\",\"croston\", \"prophet\",\"EDM\",\"naive\",\"ExpSmooth\",\"theta\",\"fft\"]\n",
        "\n",
        "resultado_final_smape= pd.concat([pd.DataFrame.from_dict(smape_arima,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_croston,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_prophet,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_EDM,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_naive,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_ExponentialSmoothing,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_Theta,orient='index'),\n",
        "           pd.DataFrame.from_dict(smape_FFT,orient='index')   \n",
        "           ], axis=1)\n",
        "resultado_final_smape.columns=[\"arima\",\"croston\", \"prophet\",\"EDM\",\"naive\",\"ExpSmooth\",\"theta\",\"fft\"]\n",
        "\n",
        "predicoes = pd.concat([pd.DataFrame.from_dict(pred_arima,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_croston,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_prophet,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_EDM,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_Naive,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_ExponentialSmoothing,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_Theta,orient='index'),\n",
        "           pd.DataFrame.from_dict(pred_FFT,orient='index')   \n",
        "           ], axis=0)\n",
        "predicoes['modelos']= [\"arima\"]*len(pred_arima) + ['croston']*len(pred_croston) + [\"prophet\"]*len(pred_prophet) + [\"EDM\"]*len(pred_EDM) + ['naive']*len(pred_Naive) + ['ExpSmooth']*len(pred_ExponentialSmoothing) + ['theta']*len(pred_Theta) + ['fft']*len(pred_FFT)\n",
        "\n",
        "erros_diff = pd.concat([pd.DataFrame.from_dict(diff_arima,orient='index'),\n",
        "           pd.DataFrame.from_dict(diff_croston,orient='index'),\n",
        "           pd.DataFrame.from_dict(diff_prophet,orient='index'),\n",
        "           pd.DataFrame.from_dict(diff_EDM,orient='index'),\n",
        "           pd.DataFrame.from_dict(diff_Naive,orient='index'),\n",
        "           pd.DataFrame.from_dict(diff_ExponentialSmoothing,orient='index'),\n",
        "           pd.DataFrame.from_dict(diff_Theta,orient='index'),\n",
        "           pd.DataFrame.from_dict(diff_FFT,orient='index')   \n",
        "           ], axis=1)\n",
        "erros_diff.columns=[\"arima\",\"croston\", \"prophet\",\"EDM\",\"naive\",\"ExpSmooth\",\"theta\",\"fft\"]\n",
        "\n",
        "resultado_final.to_csv('/content/drive/MyDrive/JOB-Martins/rfesultado_final.csv')\n",
        "resultado_final_mape.to_csv('/content/drive/MyDrive/JOB-Martins/mape.csv')\n",
        "resultado_final_smape.to_csv('/content/drive/MyDrive/JOB-Martins/smape.csv')\n",
        "predicoes.to_csv('/content/drive/MyDrive/JOB-Martins/predicoes.csv')\n",
        "erros_diff.to_csv('/content/drive/MyDrive/JOB-Martins/erros_diff.csv')\n",
        "\n",
        "print('Cmplete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "t0g4DSR3XxYc",
        "outputId": "1e2f9b79-5b17-4e91-d2ca-a9b596a35a3d"
      },
      "source": [
        "erros_diff"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-605bc94ecbbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merros_diff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'erros_diff' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ8BeCSgYcCG"
      },
      "source": [
        "#resultado_final.to_csv('/content/drive/MyDrive/JOB-Martins/rfesultado_final.csv')\n",
        "resultado_final_mape.to_csv('/content/drive/MyDrive/JOB-Martins/mape.csv')\n",
        "resultado_final_smape.to_csv('/content/drive/MyDrive/JOB-Martins/smape.csv')\n",
        "predicoes.to_csv('/content/drive/MyDrive/JOB-Martins/predicoes.csv')\n",
        "erros_diff.to_csv('/content/drive/MyDrive/JOB-Martins/erros_diff.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT4N_TQmYt18",
        "outputId": "c081d3ae-1119-4f7a-81c7-fbb78944bdbd"
      },
      "source": [
        ""
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06457822418024496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxmHOjv-Ytlk",
        "outputId": "0e785571-9fa2-41b7-a6b2-d345e58d2c16"
      },
      "source": [
        ""
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2592.5015076914497"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MbPDCVGb-ad",
        "outputId": "55b77aa6-bced-4995-a3fb-a700f90a779a"
      },
      "source": [
        ""
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35048.48999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    }
  ]
}